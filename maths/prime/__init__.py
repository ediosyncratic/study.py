"""Package to handle the lazy infinite list of primes.

A counting number is a prime if its only divisors are 1 and itself.  Formally,
every integer n generates an ideal {n*i: i is an integer} and an integer is a
prime if its ideal is a proper sub-set of the integers (which is the ideal
generated by 1)and of no other ideal.  From this, one can infer that every
positive integer may be expressed as a product of primes, raised to various
powers.  It can also be shown (quite easilly) that, for any finite set of
primes, there is a prime not in the set (this amounts to saying there are
infinitely many primes); simply multiply the given primes together and add one
to obtain a number which is not a multiple of any of the given primes; when it
is written as a product of primes, the primes used are thus not in your set.

To determine whether a positive number is a prime, one must check to see if any
integer greater than 1 divides it.  Since only smaller numbers *can* divide it,
one only needs to check smaller numbers.  Since any divisor's divisors shall
divide it, we only need to check *primes* smaller than our candidate prime.
Furthermore, if n does have a factor then it is n = i * j for some i and j; and
min(i, j) is then sure to be no greater than the square root of n; any prime
factor of min(i, j) is thus necessarily no greater than n's square root.  Thus
we only actually have to check for divisors among the primes whose squares do
not exceed the candidate.  See sieve.py for code to check a range of the
naturals looking for primes.

When checking an individual number, to determine whether it is a prime, I first
iterate through the already-known primes with squares less than it, checking
each as a candidate factor.  If we find a factor, it's not prime.  If all primes
up to its square root are known and we find no factor, it's prime.  Otherwise,
for all numbers below some cut-off, we know whether or not they're prime; our
candidate exceeds the square of that cut-off.  We may know some primes beyond
that cut-off, so it's worth checking all of these (even those whose squares
exceed our candidate) before going onwards.  Lacking a factor at this point, we
begin (or resume) work on sieving the numbers between the cut-off and some new
cut-off whose square is slightly above our candidate, albeit we might do this in
several steps rather than trying to do it all at once.  When we've finished
sieving out multiples, in this range, of the prime p we know all primes up tp
p*p; as this extends our list of known primes, we check our candidate against
new entries; if we find a factor, we suspend the sieve (leave it to be resumed
next time we need to extend our range).

One could also resort to some clever number-theoretic tricks, which provide
computationally cheap tests which will, with probability very close to one
(closer than the probability of a determinist check completing without being
perturbed by cosmic rays or other hardware errors), spot a non-prime with much
less computational effort than would be needed to actually find a divisor.
These depend on raising randomly chosen values to carefully chosen powers modulo
the alleged prime (or possibly some related numbers, I'm not familiar with the
details) and checking the results against the value that should result if the
number were a prime; for example, for any prime p and natural n which is not a
multiple of p, n**(p-1) is 1 modulo p.  However, these techniques are not (yet)
used here, since my interest is principally in factorising values, rather than
determining whether they are primes.

Note (see Eureka 45, The Riemann Hypothesis, Mark Coleman) that the number of
primes <= x grows with x as x/ln(x) or, for better precision, integral(:
dt/ln(t) &larr;t, 2<=t<=x :{reals}).  Consequently, the number of primes between
t and t+N for N small compared to t is about N/ln(t).

Various potential improvements on existing ../primes.py:

 * Turn it all into a separate sub-package, maths/prime/ !
    - abandon the misleading 'generalization' of lazyTuple; be entirely focussed
      on a lazy tuple of primes.  In particular, the grow() protocol is
      inappropriate.

 * Store factorisation information.  The sieve can be used to record a prime
   factor of each non-prime; with care, the lowest.  This should limit growth of
   size of files recording this information.  The octet-based approach can still
   be used (saving a tuple instead of a byte string); we know everything not
   represented by the octets is a multiple of one of the (few) primes defining
   our octet-block.  Store factor information in separate cache files from
   prime-ness information; they're bigger, so it may be worth breaking into
   shorter chunks.

 * Iterator support:
   - Support interface in existing class.
   - By providing an iterator class.
   - Use this iterator class in the computation of new primes.

 * Bootstrap:
   - Initialize the first sieve as [0,1] + [None]*0x80000, sieve it.
   - Set up infrastructure for using slabs - the generalized octets derived from
     the primes up to the point (17) where the next one would take us past the
     end of this sieve.
   - Save these first few primes as an overt tuple in a cache file with the
     first slab; save the sieve itself (the factor tuple) to a separate factor
     cache file.
   - Snip off the tail that left; extend it to a multiple of the slab-span and
     get on with processing.

 * Cache improvements:
   - Ensure that all uses load from cache in preference to working out afresh
     (current .grow()-based approach doesn't).
   - Use hex in file-names, rather than base ten.
   - Support use of sub-directories in the cache to provide a hierarchical cache;
     avoid over-large individual directories.
   - Add a variable second letter to file-name prefix; change each time we add a
     digit to start index (so ls gets order right); allow to wrap round a-z
     since we should be in a separate sub-dir by then !
   - Think in terms of writing a .so module to implement crucial parts, when
     implementing octet format.
   - Want the generalized-octet class to be holding o(1MB) of infrastructure
     information, notably the list of numbers coprime to the first few primes,
     modulo the product of those primes;
     + the first 132096 primes take up > 1MB in memory;
     + the primes up to 19 yield a generalized octet requiring more than that
       many coprimes, so likely taking up > 1MB in memory;
     + so limit block size to the 11520 kB blocks generated by the primes up to
       17, each with a span of 510510.
   - Retain *one* old-style cache file for the strays (which have no place in
     octet format); potentially this is the __init__.py in the root directory.
   - We'll eventually reach a point where simply remembering a list of primes
     (minus chunk start-point) is more efficient than the octets, simply because
     they're sparse enough; but the octet form shall by then be highly
     compressible, so we can use zlib on it.
   - Turn primary object into a holder for objects describing sub-ranges; load
     and unload these as needed, to limit how much is held in memory; iterators
     need to remember their positions in terms of chunk identification and
     offset, since chunk may get unloaded between next()s and file hierarchy may
     get re-organized so the chunk's file-name has changed.
   - Support for list of read-only caches from which to borrow data; default
     from $STUDY_PRIME_PATH else empty.
   - Change default prime cache dir; $STUDY_PRIME_DIR else ~/.study/prime/
   - Have separate least proper factor caches; STUDY_FACTOR_DIR defaults to
     ~/.study/factor/; and search $STUDY_FACTOR_PATH for read-only caches.
     + cope with the possibility that the user may chose to use one directory
       to cache both kinds of data.
   - Support (at least initially) digesting an old-style cache dir's data so
     that we can save it into the new cache format.
     + although this lacks the proper factor information, it still lets us
       obtain that relatively cheaply

 * Miscellaneous
   - After exhausting factorise()'s trawl through known primes, try around the
     number's (approximate) square root (see 'Conjecture' in ../primes.py).

Cache design (for each of prime and factor caches):

 * Use one modifiable cache supported by a sequence of read-only caches
   - Files in the modifiable cache, once created, only change when renamed,
     which may prompt meta-data changes (base offset for ranges of indices and
     values have changed) but not changes to their meaning.
   - Directories in the modifiable cache are wont to be reshuffled: when a
     directory has too many entries, separate them into sub-directories.
   - I may also need cache objects (in memory) representing gaps; these are
     created when a search of all caches fails to turn up anyone who can answer
     some given range; if their content is ever needed, the primes list has to
     sieve the gap and extend the modifiable cache to replace the gap object.
   - Iteration over cache objects is a tree-walking iteration, not iteration
     over the primes they describe.  A loaded cache file object owns a sub-list
     of the primes which can be iterated.

 * Each node (file or directory) in the hierarchy remembers the ranges of
   indices and values it spans; there may be gaps in its range, but it knows at
   least an initial and final chunk within its range.
   - It knows which integers in its value range are and aren't primes; for each
     prime, it knows its index as a prime.
   - Its name reflects its value range (relative to parent); to discover its
     index range, you need to load it, unless you can infer its index range from
     neighbours you've loaded, or from its parent.

 * If I care about size of cache nodes, each should record an indicator of the
   amount of memory it cost us to load() it.  This includes the memory to create
   any husk sub-objects it uses to describe any children, but not the memory
   involved in loading the children; and doesn't include any such husk memory of
   its own, that's been attributed to its parent.  Equip nodes with a method to
   return total memory used by self and all descendants.

 * Instead of an LRU cache, use weakref for all references to children (but
   normal references for references to parents) in the node hierarchy; leave
   python's garbage collection to deal with the rest.  Iterators, and other true
   clients of a node, have true references to the node, so keep it in memory;
   and hence keep all its ancestors in memory.

 * Finding desired cache objects is done by calling a method on a cache root
   object, passing it an index and/or a value, plus an optional gap object.
   - If both index and value are passed, index is ignored.
   - If the cache contains a file which handles the index or value, it returns
     an object describing that file.
   - Otherwise, if no gap object was given, a read-only cache returns None but a
     modifiable cache returns a gap object describing the interval between its
     highest file below the desired index and value and its lowest file (if any)
     above.
   - The gap object returned on failure by the modifiable cache is passed with
     queries to the read-only caches; if they have cache objects within the gap,
     they return a narrowed gap object; otherwise, they return the gap object
     unchanged.

 * The Master (modifiable root) cache object
   - should probably have (and honour) a lock-file
   - manages coversion of gap objects to sieve objects which, when completed,
     get turned into cache file objects
   - has a method by which we can give it more cache root objects, e.g. based on
     an URL (which won't fit nicely in our cache-path environment variable, due
     to its internal punctuators).

Special cases:

  * When is pow(2,n)+1 a prime ?  When n is in (1,2,4,8,16) and then no more, at
    least as far as 42.  Note that pow(2,32)+1 is 641*6700417

  * When is pow(2,n)-1 a prime ?  Never with n even; and n=1 gives 1.  When n is
    in (3,5,7,13,17,19,31) and then no more, at least as far as 60
    - Observe 31=pow(2,5)-1, 17=pow(2,4)+1, 7=pow(2,3)-1, 5=pow(2,2)+1, with
      pow(2,1)-1=1.
    - So when is pow(2, pow(2,i)+pow(-1,i))-1 a prime ?  For i=1 we get 1 which
      we ignore, then for i in (2,3,4,5,6) we get primes.

  * For prime p, if p**2 + n is prime for some natural n then: n is not 0; for q
    in {2, 3}, (n+1)%q is not zero unless p == q; otherwise, n is even, n%6
    isn't 2 and, for n <= 210, I've found it easy to find moderately large
    members of {primes p: p**2+n is prime}, so I conjecture that this set is
    infinite.

  * primes.factorise(1535694353829581938477229739693926457830L) was too much for
    this computer to handle with the old system.  Being able to cope with it is
    a crucial test of the new system.

$Id: __init__.py,v 1.6 2008-06-08 23:27:05 eddy Exp $
"""

failure_log = '''
Python 2.4.4 (#2, Apr 15 2008, 23:43:20) 
[GCC 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> from study.maths.primes import primes
>>> 2147483647L * 145295143558111L * 4921798434112837L + 1
1535694353829581938477229739693926457830L
>>> primes.factorise(_)

Process python stopped (signal)

Process python killed
'''

# from sequence import primes
# so you can: from study.maths.prime import primes
# See also: study.maths.prime.tool (once I've renamed ../primes.py and pruned it)
# Notably, iterating its Sisyphus is one way to expand your cache.
